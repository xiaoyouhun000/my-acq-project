{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import request\n",
    "import re\n",
    "import csv\n",
    "import os.path\n",
    "import time\n",
    "import datetime\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "http.client.HTTPConnection._http_vsn = 10\n",
    "http.client.HTTPConnection._http_vsn_str = 'HTTP/1.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readfromweb(year, quarter):\n",
    "\n",
    "    data = urllib.request.urlopen(\"https://www.sec.gov/Archives/edgar/full-index/%s/QTR%s/company.idx\" %(year, quarter))\n",
    "    datastring = data.read()\n",
    "\n",
    "    return datastring\n",
    "\n",
    "def readfromfile(year, quarter):\n",
    "    with open(\"%s_%s.idx\" %(year, quarter), \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def writecsv(l, filename):\n",
    "\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(l)\n",
    "\n",
    "def readindex(year, quarter):\n",
    "\n",
    "    if not os.path.exists(\"%s_%s.idx\" %(year, quarter)):\n",
    "        with open(\"%s_%s.idx\" %(year, quarter), \"wb\") as f:\n",
    "            f.write(readfromweb(year, quarter))\n",
    "\n",
    "    print(\"readfromweb complete\")\n",
    "\n",
    "    data = readfromfile(year, quarter)\n",
    "\n",
    "    print(\"readfromfile complete\")\n",
    "    \n",
    "    datalines = data.split(\"\\n\")\n",
    "    assert re.match(\"^-+$\", datalines[9])\n",
    "    datakeep = []\n",
    "    datareject = []\n",
    "    i = 0\n",
    "    for line in datalines[10:]:\n",
    "        companyName = line[0:62].strip()\n",
    "        formTypes = line[62:74].strip()\n",
    "        CIK = line[74:86].strip()\n",
    "        date = line[86:98].strip()\n",
    "        URL_10k = line[98:].strip()\n",
    "        if re.search('10[ -]?[kK]', formTypes) and not re.search('NT', formTypes):\n",
    "            datakeep.append([companyName, formTypes, CIK, date, URL_10k])\n",
    "        else:\n",
    "            datareject.append([companyName, formTypes, CIK, date, URL_10k])\n",
    "\n",
    "        i=i+1\n",
    "##        if i==100:\n",
    "##            ##print(datakeep)\n",
    "##            break\n",
    "    writecsv(datakeep, \"%s_%s.csv\" %(year, quarter))\n",
    "    writecsv(datareject, \"%s_%s_rej.csv\" %(year, quarter))\n",
    "\n",
    "\n",
    "def readforms(year, quarter):\n",
    "\n",
    "##    global alternate_exists\n",
    "##    print(mode)\n",
    "\n",
    "    with open(\"%s_%s.csv\" %(year, quarter), \"r\") as URLfile:\n",
    "        datareader = csv.reader(URLfile)\n",
    "        name = []\n",
    "        cik = []\n",
    "        date = []\n",
    "        URLs = []\n",
    "        forms = []\n",
    "        for row in datareader:\n",
    "            URLs.append(row[4])\n",
    "            forms.append(row[1])\n",
    "            name.append(row[0])\n",
    "            cik.append(row[2])\n",
    "            date.append(row[3])\n",
    "    datamax=0\n",
    "    \n",
    "    problems = []\n",
    "    rowtowrite=[]\n",
    "    rowtowrite.append([\"CIK\",\n",
    "                       \"Name\",\n",
    "                       \"Form\",\n",
    "                       \"Filing date\",\n",
    "                       \"Filing year\",\n",
    "                       \"Filing quarter\",\n",
    "                       \"URL of form\",\n",
    "                       \"public float 1\",\n",
    "                       \"public float 2\",\n",
    "                       \"extract\",\n",
    "                       \"point of public float\",\n",
    "                       \"position of something...\",\n",
    "                       \"checkbox extract\",\n",
    "                       \"LAF\", \"AF\", \"NAF\", \"SRC\",\n",
    "                       \"LAF2\", \"AF2\", \"NAF2\", \"SRC2\",\n",
    "                       \"Filing status\",\n",
    "                       \"FYenddate\",\n",
    "                       \"FY year\",\n",
    "                       \"Filer status, alternate\",\n",
    "                       \"Accelerated filer status, pre-2005\",\n",
    "                       \"Filing status 2\"])\n",
    "    parser_set = [\"html.parser\", \"html5lib\", \"lxml\"]\n",
    "    checkboxtestset = [\"whether the registrant is a large accelerated\",\n",
    "                       \"whether registrant is a large accelerated\",\n",
    "                       \"if the registrant is a large accelerated\",\n",
    "                       \"if the company is a large accelerated\",\n",
    "                       \"if company is a large accelerated\",\n",
    "                       \"if registrant is a large accelerated\",\n",
    "                       \"is one of the following: (1) large accelerated\",\n",
    "                       \"whether each registrant is a large accelerated\",\n",
    "                       \"if each registrant is a large accelerated\"]                       \n",
    "    accfilchecks = [\"the agg\",\n",
    "                    \"state\",\n",
    "                    \"the appro\",\n",
    "                    \" at \",\n",
    "                    \"based\",\n",
    "                    \"indicate\",\n",
    "                    \" on \",\n",
    "                    \"(1)\",\n",
    "                    \"aggregate\",\n",
    "                    \" 1 \",\n",
    "                    \"-1-\",\n",
    "                    \".---\",\n",
    "                    \"as the reg\",\n",
    "                    \"table\",\n",
    "                    \"the common\",\n",
    "                    \"the registrant\",\n",
    "                    \"the number\",\n",
    "                    \"the issuer\",\n",
    "                    \"explanatory\",\n",
    "                    \"-at\",\n",
    "                    \"*this\",\n",
    "                    \"* this\",\n",
    "                    \"the market\",\n",
    "                    \"market\",\n",
    "                    \"issuer\",\n",
    "                    \"registrant does\",\n",
    "                    \"non-aff\",\n",
    "                    \"for the year\",\n",
    "                    \"cover\",\n",
    "                    \"form 10\",\n",
    "                    \"registrant had\",\n",
    "                    \"all of\",\n",
    "                    \"part i item\",\n",
    "                    \"there is \",\n",
    "                    \"there were\",\n",
    "                    \"see page\",\n",
    "                    \"this doc\",\n",
    "                    \"applicable\",\n",
    "                    \"the company\",\n",
    "                    \"upon\",\n",
    "                    \"-----\",\n",
    "                    \"the closing\",\n",
    "                    \"number of\",\n",
    "                    \"shares of\",\n",
    "                    \"wholly\",\n",
    "                    \"while\",\n",
    "                    \"-on\",\n",
    "                    \"no voting\",\n",
    "                    \"this annual\",\n",
    "                    \"none of\",\n",
    "                    \"page\",\n",
    "                    \"all outstanding\",\n",
    "                    \"all common\",\n",
    "                    \"registrant has\",\n",
    "                    \"the members\",\n",
    "                    \"portions of\",\n",
    "                    \"the limited\",\n",
    "                    \"because\",\n",
    "                    \"[cover\",\n",
    "                    \"the [\",\n",
    "                    \"common stock\",\n",
    "                    \"revenues\",\n",
    "                    \"(form\",\n",
    "                    \"nbsp\"]\n",
    "    chbxts = [\"(check one):\",\n",
    "              \"(check one).\",\n",
    "              \"(check one)\",\n",
    "              \"12b-2).\",\n",
    "              \"12b-2.\",\n",
    "              \"exchange act.\",\n",
    "              \"exchange act:\",\n",
    "              \"exchange act).\",\n",
    "              \"exchange act):\",\n",
    "              \"exhange act)\",\n",
    "              \"exchange act .\",\n",
    "              \"of the act).\",\n",
    "              \"of the act.\",\n",
    "              \"or a smaller reporting company.\",\n",
    "              \"or a smaller reporting company:\",\n",
    "              \"or a non-accelerated filer.\",\n",
    "              \"or a non-accelerated filer:\",\n",
    "              \"of 1934:\",\n",
    "              \"of 1934).\",\n",
    "              \"of 1934.\",\n",
    "              \"of 1934)\",\n",
    "              \"of 1934\",\n",
    "              \"of the exchange act\",\n",
    "              \"or a smaller reporting company\",\n",
    "              \"or a non-accelerated filer\",\n",
    "              \"12b-2\",\n",
    "              \"12b\"]\n",
    "\n",
    "##    print(\"rowwritten\")\n",
    "##    URLs = [\"edgar/data/702259/0000950148-03-000640.txt\"]\n",
    "\n",
    "    for i in range(len(URLs)):   ## set to range(1000) when running abbreviated\n",
    "##        if i<5195:\n",
    "##            continue\n",
    "        largest = \"none\"\n",
    "        trymarker= 0\n",
    "##        if quarter == 1:\n",
    "##            continue\n",
    "##        if i<5205:\n",
    "##            continue\n",
    "##        if i>80:\n",
    "##            continue\n",
    "##        print(i)\n",
    "        filingstatus = \"\"\n",
    "        filingstatus2 = \"\"\n",
    "        FYenddate = \"\"\n",
    "        FY_year = \"\"\n",
    "        pointofPF = 0\n",
    "        FYenddatechecks = [\" or \",\n",
    "                           \" |\",\n",
    "                           \"-\",\n",
    "                           \"transition report\",\n",
    "                           \" [\",\n",
    "                           \" _\",\n",
    "                           \".\",\n",
    "                           \" file\",\n",
    "                           \" commission\",\n",
    "                           \" restated\"]\n",
    "        mktval=\"blank market val\"\n",
    "        largest = \"blank largest val\"\n",
    "        bartsection = \"\"\n",
    "\n",
    "                           \n",
    "        LAF2 = \"\"\n",
    "##        print(\"inside for loop\")\n",
    "##        print(URLs[i])\n",
    "        try:\n",
    "            data = urllib.request.urlopen(\"http://www.sec.gov/Archives/%s\" %(URLs[i]), timeout=10).read(100000)\n",
    "##            print(type(data))\n",
    "##        print(\"URL opened\")\n",
    "        ##souptext = str(data)\n",
    "        except urllib.error.URLError:\n",
    "            data = \" \"\n",
    "            rowtowrite.append([cik[i], name[i], forms[i], date[i], year, quarter, \"http://www.sec.gov/Archives/%s\" %(URLs[i]), \"timeout error\"])\n",
    "            continue\n",
    "        except KeyboardInterrupt:\n",
    "            raise KeyboardInterrupt\n",
    "        except:\n",
    "            rowtowrite.append([cik[i], name[i], forms[i], date[i], year, quarter, \"http://www.sec.gov/Archives/%s\" %(URLs[i]), \"other URL reading error\"])\n",
    "            continue\n",
    "        try:\n",
    "            souptext = data.decode('utf-8')\n",
    "##            tabcon = souptext.find(\"TABLE OF CONTENTS\")\n",
    "##            if tabcon != -1: \n",
    "##                souptext = souptext[0:tabcon+1]\n",
    "            docref = souptext.find(\"DOCUMENTS INCORPORATED BY REFERENCE\")\n",
    "            if docref != -1:\n",
    "                souptext = souptext[0:docref+1]\n",
    "            souptextup = souptext.upper()\n",
    "            \n",
    "            p1 = souptext.find(\"PART I ITEM 1\")\n",
    "            if p1 != -1:\n",
    "                souptext = souptext[0:p1]\n",
    "            docref = souptextup.find(\"DOCUMENTS INCORPORATED BY REFERENCE\")\n",
    "            if docref != -1:\n",
    "                souptext = souptext[0:docref+1]\n",
    "##            jpegloc = souptextup.find(\".JPG\")\n",
    "##            if jpegloc !=-1:\n",
    "##                souptext = souptext[0:jpegloc+1]\n",
    "##            else:\n",
    "####                print(i)\n",
    "####                print(\"it wasn't found!\")\n",
    "##                if len(souptext)>50000:\n",
    "##                    souptext = souptext[0:49999]\n",
    "            souptextforparse = souptext\n",
    "            for parsing in parser_set:\n",
    "##                print(parsing)\n",
    "                try:\n",
    "                    soup = BeautifulSoup(souptextforparse, parsing)\n",
    "                    break\n",
    "    ##            print(\"souped\")\n",
    "                except RuntimeWarning:\n",
    "                    print(\"RUNTIME WARNING EXCEPTION!!!!!!!!!!!!!!!!!\")\n",
    "                    if parsing == \"html5lib\":\n",
    "                        souptext = \" \"\n",
    "                        soup = \" \"\n",
    "##                    print(URLs[i])\n",
    "                    problems.append([year, quarter, URLs[i], \"runtime warning exception\"])\n",
    "                    continue\n",
    "                except KeyboardInterrupt:\n",
    "                    raise KeyboardInterrupt\n",
    "                except:\n",
    "                    print(\"EXCEPTION!!!!!!!!!!!!!!!!!\")\n",
    "                    if parsing == \"html5lib\":\n",
    "                        souptext = \" \"\n",
    "                        soup = \" \"\n",
    "##                    print(URLs[i])\n",
    "                    problems.append([year, quarter, URLs[i], \"parser exception 1\"])\n",
    "                    continue\n",
    "##            print(len(souptext))\n",
    "##            data.close()\n",
    "\n",
    "                \n",
    "##            if i==16:\n",
    "##                print(souptext)\n",
    "            souptext = soup.get_text(\" \", strip=True)\n",
    "\n",
    "##            if i==16:\n",
    "##                print(souptext)\n",
    "            \n",
    "            souptext = souptext.replace(\"\\\\n\", \" \")\n",
    "            souptext = souptext.replace(\"\\n\", \" \")\n",
    "            souptext = souptext.replace(\"Series\", \" Series\")\n",
    "            souptext = souptext.replace(\"$ \", \"$\")\n",
    "            souptext = souptext.replace(\"$_\", \"$0 \")\n",
    "            souptext = souptext.replace(\" \", \" \")\n",
    "            souptext = souptext.replace(\".(\", \". (\")\n",
    "            souptext = souptext.replace(u'\\xa0', u' ')\n",
    "            souptext = souptext.replace(\"non &#150;acc\", \"non-acc\")\n",
    "            souptext = souptext.replace(\"$-0-\", \"$0\")\n",
    "            souptext = souptext.replace(\"nonaffiliates\", \"non-affiliates\")\n",
    "            souptext = souptext.replace(\"nonaccelerated\", \"non-accelerated\")\n",
    "            souptext = souptext.replace(\"Non accelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"Non Accelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"non accelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"Nonaccelerated\", \"Non-accelerated\")\n",
    "            souptext = souptext.replace(\"12(b)-2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"12(b)2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"12-b2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"12-b-2\", \"12b-2\")\n",
    "            souptext = souptext.replace(\"filler\", \"filer\")\n",
    "            souptext = souptext.replace(\"$USD\", \"$\")\n",
    "            souptext = souptext.replace(\"USD\", \"$\")\n",
    "            souptext = souptext.replace(\"$US\", \"$\")\n",
    "            souptext = souptext.replace(\"$$\", \"$\")\n",
    "            souptext = souptext.replace(\"$ \", \"$\")\n",
    "            souptext = souptext.replace(\"&nbsp;\", \" \")\n",
    "            souptext = \" \".join(souptext.split())\n",
    "\n",
    "            souptextlower = souptext.lower()\n",
    "##            if i==16:\n",
    "##                print(souptext)\n",
    "\n",
    "\n",
    "            pointofPF=souptextlower.find(\"non-affiliates\")\n",
    "            \n",
    "            donotcheckfind = souptextlower.find(\"(do not check\", souptextlower.find(\"accelerated\"))\n",
    "            if donotcheckfind<0:\n",
    "                donotcheckfind = souptextlower.find(\"(do not mark\", souptextlower.find(\"accelerated\"))\n",
    "            donotcheckend = souptextlower.find(\")\", donotcheckfind)\n",
    "            if donotcheckfind>0:\n",
    "                souptext = souptext.replace(souptext[donotcheckfind:donotcheckend+1], \"\")\n",
    "            souptext = \" \".join(souptext.split())\n",
    "\n",
    "\n",
    "##            tabcon = souptext.find(\"TABLE OF CONTENTS\")\n",
    "##            if tabcon != -1: \n",
    "##                souptext = souptext[0:tabcon+1]\n",
    "            p1 = souptext.find(\"PART I ITEM 1\")\n",
    "            if p1 != -1:\n",
    "                souptext = souptext[0:p1]\n",
    "            docref = souptext.find(\"DOCUMENTS INCORPORATED BY REFERENCE\")\n",
    "            if docref != -1:\n",
    "                souptext = souptext[0:docref+1]\n",
    "            souptextup = souptext.upper()\n",
    "            docref = souptextup.find(\"DOCUMENTS INCORPORATED BY REFERENCE\")\n",
    "            if docref != -1:\n",
    "                souptext = souptext[0:docref+1]\n",
    "\n",
    "            souptext = \" \".join(souptext.split())\n",
    "\n",
    "##            print(\"soup replacements made\")\n",
    "            \n",
    "            souptext_noascii = removeNonAscii(souptext)\n",
    "            souptext_noascii = souptext_noascii.replace(\"non- aff\", \"non-aff\")\n",
    "            souptext_noascii = souptext_noascii.replace(\"non aff\", \"non-aff\")\n",
    "            souptext_noascii = \" \".join(souptext_noascii.split())\n",
    "        \n",
    "            lct =  (souptext_noascii.find(\"held by non-affiliates\"))\n",
    "##            if lct != -1:\n",
    "##                break\n",
    "            if lct == -1:\n",
    "                lct = souptext_noascii.find(\"by non-affiliates\")\n",
    "            pos = souptext_noascii.find(\"$\", lct)\n",
    "##            pointofPF = pos\n",
    "            souptextlower = souptext_noascii.lower()\n",
    "            souptext2 = souptext\n",
    "            souptext = souptext_noascii\n",
    "\n",
    "##            if i ==16:\n",
    "##                print(souptext)\n",
    "\n",
    "            if lct==-1:\n",
    "                if souptextlower.find(\"no public market for the registrant’s common stock\")>0:\n",
    "                    mktval = \"no public market\"\n",
    "                elif souptextlower.find(\"no definition available\", lct-200, lct+400)>0:\n",
    "                    mktval = \"no definition available\"\n",
    "                elif souptextlower.find(\"because the registrant is a wholly-owned subsidiary\")>0:\n",
    "                    mktval = \"wholly owned subsidiary\"\n",
    "                elif souptextlower.find(\"none of the registrant's outstanding voting stock is held by non-affiliates\")>0:\n",
    "                    mktval = \"none held by non-affiliates\"\n",
    "                elif souptextlower.find(\"registrant has no voting common equity\")>0:\n",
    "                    mktval = \"no voting common equity\"\n",
    "                elif souptextlower.find(\"no established public trading market for registrant’s units\")>0:\n",
    "                    mktval = \"no public trading market\"\n",
    "                elif souptextlower.find(\"there are no non-affiliate shareholders of the registrant.\")>0:\n",
    "                    mktval = \"no non-affiliates\"\n",
    "                else:\n",
    "                    mktval = \"not given\"\n",
    "            else:\n",
    "                souptextlower = souptext.lower()\n",
    "                if pos-lct>700 or pos==-1:\n",
    "                    if souptextlower.find(\"no public market for the registrant’s common stock\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no public market\"\n",
    "                    elif souptextlower.find(\"no definition available\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no definition available\"\n",
    "                    elif souptextlower.find(\"because the registrant is a wholly-owned subsidiary\", lct-200, lct+400)>0:\n",
    "                        mktval = \"wholly owned subsidiary\"\n",
    "                    elif souptextlower.find(\"none of the registrant's outstanding voting stock is held by non-affiliates\", lct-200, lct+400)>0:\n",
    "                        mktval = \"none held by non-affiliates\"\n",
    "                    elif souptextlower.find(\"registrant has no voting common equity\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no voting common equity\"\n",
    "                    elif souptextlower.find(\"no established public trading market for registrant’s units\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no public trading market\"\n",
    "                    elif souptextlower.find(\"There are no non-affiliate shareholders of the Registrant.\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no non-affiliates\"\n",
    "                    else:\n",
    "                        mktval = \"not given\" \n",
    "                else:\n",
    "                    if souptextlower.find(\"no public market for the registrant’s common stock\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no public market\"\n",
    "                    elif souptextlower.find(\"no definition available\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no definition available\"\n",
    "                    elif souptextlower.find(\"because the registrant is a wholly-owned subsidiary\", lct-200, lct+400)>0:\n",
    "                        mktval = \"wholly owned subsidiary\"\n",
    "                    elif souptextlower.find(\"none of the registrant's outstanding voting stock is held by non-affiliates\", lct-200, lct+400)>0:\n",
    "                        mktval = \"none held by non-affiliates\"\n",
    "                    elif souptextlower.find(\"registrant has no voting common equity\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no voting common equity\"\n",
    "                    elif souptextlower.find(\"no established public trading market for registrant’s units\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no public trading market\"\n",
    "                    elif souptextlower.find(\"There are no non-affiliate shareholders of the Registrant.\", lct-200, lct+400)>0:\n",
    "                        mktval = \"no non-affiliates\"\n",
    "                    basedonstr = souptext[lct:pos]\n",
    "                    basedon = basedonstr.find(\"price\")\n",
    "                    if basedon != -1:\n",
    "                        pos = souptext.find(\"$\", souptext.find(\"was\", basedon+lct))\n",
    "                        if pos == -1:\n",
    "                            pos = souptext.find(\"$\", souptext.find(\":\", basedon+lct))\n",
    "##                    if i%100==0:\n",
    "##                        print(souptext[pos:pos+500])\n",
    "                    spc = souptext.find(\" \", pos)\n",
    "                    ##print(basedonstr)\n",
    "                    ##print(basedon)\n",
    "                    ##print(souptext[pos+1:spc])\n",
    "                    try:\n",
    "                        mktval = float(souptextlower[pos+1:spc].replace(\",\",\"\").rstrip(\".\").replace(\"*\",\"\").replace(\";\",\"\"))\n",
    "                        if mktval<10000:\n",
    "                            nxtword = isitmln(souptextlower, pos)\n",
    "                            if nxtword == \"million\":\n",
    "                                mktval = mktval*(10**6)\n",
    "                            elif nxtword == \"billion\":\n",
    "                                mktval = mktval*(10**9)\n",
    "                            else:\n",
    "                                newpos = souptextlower.find(\"$\", spc)\n",
    "                                newspc = souptextlower.find(\" \", newpos)\n",
    "                                ##print(souptext[newpos+1:newspc])\n",
    "                                try:\n",
    "                                    mktval = float(souptextlower[newpos+1:newspc].replace(\",\",\"\").rstrip(\".\").replace(\"*\",\"\").replace(\";\",\"\"))\n",
    "                                    nxtword = isitmln(souptextlower, newpos)\n",
    "                                    if nxtword == \"million\":\n",
    "                                        mktval = mktval*(10**6)\n",
    "                                    elif nxtword == \"billion\":\n",
    "                                        mktval = mktval*(10**9)\n",
    "                                    else:\n",
    "                                        mktval = \"not given\"\n",
    "                                except ValueError:\n",
    "                                    mktval = \"exception 2\"\n",
    "\n",
    "                    except ValueError:\n",
    "                        mktval = \"error converting to float\"\n",
    "                snippet = souptextlower[lct-50:lct+700]\n",
    "                lrgstval = []\n",
    "                for match in re.finditer(\"\\$\", snippet):\n",
    "                    pnt = match.start()\n",
    "                    spce = snippet.find(\" \", pnt)\n",
    "                    try:\n",
    "                        lrgstvalapp=(float(snippet[pnt+1:spce].replace(\",\",\"\").rstrip(\".\").replace(\"*\",\"\").replace(\";\",\"\")))\n",
    "                        nxtword = isitmln(snippet, pnt)\n",
    "                        if nxtword == \"million\" and lrgstvalapp <1000000:\n",
    "                            lrgstvalapp = lrgstvalapp*(10**6)\n",
    "                        elif nxtword == \"billion\" and lrgstvalapp <1000000000:\n",
    "                            lrgstvalapp = lrgstvalapp*(10**9)\n",
    "                        lrgstval.append(lrgstvalapp)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                if lrgstval!= []:\n",
    "                    largest = max(lrgstval)\n",
    "                else:\n",
    "                    largest = \"none\"\n",
    "            souptextlower = souptextlower.replace(\"for fiscal year\", \"for the fiscal year\")\n",
    "            \n",
    "            if souptextlower.find(\"for the fiscal year ended\") >-1:\n",
    "                FYenddate = souptextlower[souptextlower.find(\"for the fiscal year ended\")+len(\"for the fiscal year ended\")+1:souptextlower.find(\"for the fiscal year ended\")+150]\n",
    "                for TRfinder in FYenddatechecks:\n",
    "                    if FYenddate.find(TRfinder)>-1:\n",
    "                        FYenddate = FYenddate[0:FYenddate.find(TRfinder)]\n",
    "                if re.search(\"[0-9]{4}\", FYenddate):\n",
    "                    matcher = re.search(\"[0-9]{4}\", FYenddate)\n",
    "                    FY_year = matcher.group()\n",
    "\n",
    "            if type(lct) is int:\n",
    "                if lct!=-1:\n",
    "                    extract = souptext[lct:lct+400]\n",
    "                else:\n",
    "                    extract = \"none\"\n",
    "            else:\n",
    "                extract = \"none, lct was not integer\"\n",
    "\n",
    "            souptext = souptext2\n",
    "\n",
    "            souptextlower = souptext.lower()\n",
    "\n",
    "            souptextendpoint = souptextlower.find(\"indicate\", souptextlower.find(\"shell\")-200)\n",
    "            souptext = souptext[0:souptextendpoint]\n",
    "            souptextlower = souptext.lower()\n",
    "            strtpt = souptextlower.find(\"accelerated\")-300\n",
    "            if strtpt>0:\n",
    "                souptextlower = souptextlower[strtpt:]\n",
    "            endptnew = souptextlower.find(\"as of\", souptextlower.find(\"accelerated\"))\n",
    "            ## NEED TO DO SOMETHING WITH THE ABOVE LINE\n",
    "            ## HAD NEEDED TO, NOW IT'S ADDED\n",
    "            if endptnew != -1:\n",
    "                souptextlower = souptextlower[:endptnew]\n",
    "            souptextlower = \" \".join(souptextlower.split())\n",
    "            \n",
    "\n",
    "            ## get the check boxes\n",
    "            checkboxes = 0\n",
    "            checkboxesmaximin = 0\n",
    "            checkextract = \"\"\n",
    "            LAF = \"\"\n",
    "            AF = \"\"\n",
    "            NAF = \"\"\n",
    "            SRC = \"\"\n",
    "            LAF2 = \"\"\n",
    "            AF2 = \"\"\n",
    "            NAF2 = \"\"\n",
    "            SRC2 = \"\"\n",
    "            filerstatus_alternate = \"\"\n",
    "            accfilerpre2005 = \"\"\n",
    "            souptextlower = souptextlower.replace(\"smaller reporting filer\", \"smaller reporting company\")\n",
    "            souptextlower = souptextlower.replace(\"small reporting company\", \"smaller reporting company\")\n",
    "            souptextlower = souptextlower.replace(\"non- accelerated\", \"non-accelerated\")\n",
    "            souptextlower = souptextlower.replace(\"no n-accelerated\", \"non-accelerated\")\n",
    "            souptextlower = souptextlower.replace(\"non accelerated\", \"non-accelerated\")\n",
    "            souptextlower = souptextlower.replace(\"nonaccelerated\", \"non-accelerated\")\n",
    "            souptextlower = souptextlower.replace(\" - \", \"-\")\n",
    "            souptextlower = souptextlower.replace(\" -\", \"-\")\n",
    "            souptextlower = souptextlower.replace(\"- \", \"-\")\n",
    "            souptextlower = souptextlower.replace(\"accelerated filed\", \"accelerated filer\")\n",
    "            souptextlower = souptextlower.replace(\"accelerate fil\", \"accelerated fil\")\n",
    "            souptextlower = souptextlower.replace(\"fil er\", \"filer\")\n",
    "            souptextlower = souptextlower.replace(\"larger accelerated\", \"large accelerated\")\n",
    "            souptextlower = souptextlower.replace(\"large, accelerated\", \"large accelerated\")\n",
    "            souptextlower = souptextlower.replace(\"accelerated file r\", \"accelerated filer\")\n",
    "            souptextlower = souptextlower.replace(\"accelerated file \", \"accelerated filer \")\n",
    "            souptextlower = souptextlower.replace(\"accelerated filter\", \"accelerated filer\")\n",
    "            donotcheckfind2 = souptextlower.find(\"(\", souptextlower.find(\"if a smaller\")-50)\n",
    "            donotcheckend2 = souptextlower.find(\")\", donotcheckfind2)\n",
    "            if donotcheckfind2 > 0 and donotcheckend2 > 0:\n",
    "                souptextlower = souptextlower.replace(souptextlower[donotcheckfind2:donotcheckend2], \" \")\n",
    "            donotcheckfind3 = souptextlower.find(\"do not check\", souptextlower.find(\"if a smaller\")-50)\n",
    "            if donotcheckfind3 >0:\n",
    "                souptextlower = souptextlower.replace(souptextlower[souptextlower.find(\"do not check\"):souptextlower.find(\"smaller reporting company\")+len(\"smaller reporting company\")], \"\")\n",
    "\n",
    "            checkone = \"\"\n",
    "            checktwo = \"\"\n",
    "            if year >=2002:\n",
    "##                acfilsection = souptextlower.replace(\"12b-2\", \"12b-2.\")\n",
    "##                acfilsection = acfilsection.replace(\"exchange act\", \"exchange act).\")\n",
    "                acfilsection = souptextlower.replace(\"yes:\", \"yes;\")\n",
    "                acfilsection = acfilsection.replace(\"no:\", \"no;\")\n",
    "                acfilsection = acfilsection.replace(\"(check mark)\", \"x\")                \n",
    "                acfilsectionpt = acfilsection.find(\"accelerated filer\")\n",
    "                if acfilsectionpt!=-1 and acfilsection.find(\"large acc\")==-1:\n",
    "                    accfilerpre2005 = acfilsection[acfilsectionpt:acfilsectionpt+200]\n",
    "                    if accfilerpre2005.find(\"yes\")!=-1:\n",
    "                        accfilerpre2005 = accfilerpre2005[:accfilerpre2005.find(\"yes\")+30]\n",
    "                    for ender in accfilchecks:\n",
    "                        afep = accfilerpre2005.find(ender)\n",
    "                        if afep != -1:\n",
    "                            accfilerpre2005 = accfilerpre2005[:afep].strip()\n",
    "                    checkone = accfilerpre2005[accfilerpre2005.find(\"yes\"):accfilerpre2005.find(\"no\")+8]\n",
    "                    rfinder = accfilerpre2005.rfind(\".\")\n",
    "                    while rfinder>accfilerpre2005.find(\"yes\") or rfinder>accfilerpre2005.find(\" no\"):\n",
    "                        accfilerpre2005 = accfilerpre2005[:rfinder] + accfilerpre2005[rfinder+1:]\n",
    "                        rfinder = accfilerpre2005.rfind(\".\")\n",
    "                    bart = min([max([accfilerpre2005.find(\")\"),accfilerpre2005.find(\".\"),accfilerpre2005.find(\":\"), accfilerpre2005.find(\"the act\")+len(\"the act\"), accfilerpre2005.find(\"of 1934\")+len(\"of 1934\"), accfilerpre2005.find(\"exchange act\")+len(\"exchange act\"), accfilerpre2005.find(\"12b-2\")+len(\"12b-2\")]), accfilerpre2005.find(\"yes\")-3, accfilerpre2005.find(\"no\")-3])\n",
    "\n",
    "                    bartsection = accfilerpre2005\n",
    "                    \n",
    "                    while bart != -1:\n",
    "                        bartsection = bartsection[bart+1:].strip()\n",
    "                        bart = max([bartsection.find(\")\"),bartsection.find(\".\"),bartsection.find(\":\"),bartsection.find(\":\")])\n",
    "                    if \"yes\" in bartsection:\n",
    "                        filingstatus2 = filercat(bartsection, 1)\n",
    "                        filingstatus = filingstatus2\n",
    "                    \n",
    "\n",
    "            if year >= 2005:\n",
    "                for chkbox in checkboxtestset:\n",
    "                    checkboxesnew = souptextlower.find(chkbox)\n",
    "                    if checkboxesnew > 0:\n",
    "                        if checkboxesmaximin == 0:\n",
    "                            checkboxesmaximin = checkboxesnew\n",
    "                        else:\n",
    "                            checkboxesmaximin = min(checkboxesnew, checkboxesmaximin)\n",
    "                checkboxes = checkboxesmaximin\n",
    "            if checkboxes>0:\n",
    "                checkextract = souptextlower[checkboxes:checkboxes+1000]\n",
    "                checkstart = checkextract.find(\"12b\")\n",
    "                if checkstart<0:\n",
    "                    checkstart = checkextract.find(\" or \", checkextract.find(\"accelerated\"))+8\n",
    "                checkext2 = checkextract[checkstart:]\n",
    "                sorter = checkextract[checkstart:].replace(\"ge acc\", \"\")\n",
    "                sorter = sorter.replace(\"n-acc\", \"\")\n",
    "\n",
    "                sorterlister = [[\"Large accelerated\", sorter.find(\"lareler\")],\n",
    "                                [\"Accelerated\", sorter.find(\"accelerated\")],\n",
    "                                [\"Non-accelerated\", sorter.find(\"noele\")],\n",
    "                                [\"Smaller reporting\", sorter.find(\"smaller\")]]\n",
    "                if checkextract.find(\"smaller reporting\")==-1:\n",
    "                    sorterlister = sorterlister[0:3]\n",
    "\n",
    "##                second_col = [row[1] for row in sorterlister]\n",
    "##                while -1 in second_col:\n",
    "##                    second_col.remove(-1)\n",
    "##                minseccol = min(second_col)\n",
    "                checkextract3 = checkextract[:]\n",
    "##                print(i)\n",
    "##                print(name[i])\n",
    "##                print(checkextract3)\n",
    "                \n",
    "                for chkr in chbxts:\n",
    "                    chkpt = checkextract3.find(chkr)\n",
    "##                    print(chkr, chkpt)\n",
    "                    if chkpt !=-1:\n",
    "                        checkextract3 = checkextract3[chkpt+len(chkr):].strip()\n",
    "##                        print(checkextract3)\n",
    "##                        print(chkr)\n",
    "##                        print(\"just revised\")\n",
    "##                print(checkextract3)\n",
    "                if len(checkextract3)>2:\n",
    "                    while (checkextract3[0]==\".\" or checkextract3[0]==\":\" or checkextract3[0]==\")\") and len(checkextract3)>2:\n",
    "                        checkextract3 = checkextract3[1:].strip()\n",
    "##                        print(checkextract3)\n",
    "\n",
    "##                checkextract = souptextlower[checkboxes:checkboxes+1000]\n",
    "##                print(checkextract)\n",
    "##                print(\"START\")\n",
    "##                print(i)\n",
    "##                print(sorterlister)\n",
    "##                print(checkextract)\n",
    "##                print(checkextract[checkstart:])\n",
    "##                print(checkextract[checkstart+minseccol:])\n",
    "##                filingstatus2 = filercat(checkextract[checkstart+minseccol:], \"laf, naf, af, src\")\n",
    "                filingstatus2 = filercat(checkextract3, \"laf, naf, af, src\")\n",
    "##                print(filingstatus2)\n",
    "##                print(i)\n",
    "##                print(\"FINISH\")\n",
    "                ## IS the line above correct?\n",
    "                if sorterlister != sorted(sorterlister, key = lambda position: position[1]):\n",
    "##                    print(\"unsorted\")\n",
    "                    problems.append([year, quarter, URLs[i], \"sorted incorrectly\", sorterlister, checkextract])\n",
    "\n",
    "                \n",
    "                if sorterlister == sorted(sorterlister, key = lambda position: position[1]):\n",
    "                    if year >=2008:\n",
    "                        find1 = checkextract.find(\"large accelerated filer\", checkstart)\n",
    "                        find2 = checkextract.find(\"accelerated filer\", find1+10)\n",
    "                        find3 = checkextract.find(\"non-accelerated\", find2+10)\n",
    "                        find4 = checkextract.find(\"smaller reporting\", find3)\n",
    "                        find5 = find4+len(\"smaller reporting company\")+10\n",
    "                        LAF = checkextract[find1:find2]\n",
    "                        AF = checkextract[find2:find3]\n",
    "                        NAF = checkextract[find3:find4]\n",
    "                        if find5>len(checkextract):\n",
    "                            SRC = checkextract[find4:]\n",
    "                        else:\n",
    "                            SRC = checkextract[find4:find5]\n",
    "                    elif year >= 2005:\n",
    "                        find1 = checkextract.find(\"large accelerated\", checkstart)\n",
    "                        find2 = checkextract.find(\"accelerated filer\", find1+10)\n",
    "                        find3 = checkextract.find(\"non-accelerated\", find2+10)\n",
    "                        find4 = checkextract.find(\"indicate\", find3)\n",
    "                        LAF = checkextract[find1:find2]\n",
    "                        AF = checkextract[find2:find3]\n",
    "                        if find4>0:\n",
    "                            NAF = checkextract[find3:find4]\n",
    "                        else:\n",
    "                            NAF = checkextract[find3:]\n",
    "                elif sorterlister[1][1]>sorterlister[2][1]:\n",
    "##                    print(sorterlister)\n",
    "##                    print(URLs[i])\n",
    "                    if year >=2008:\n",
    "                        find1 = checkextract.find(\"large accelerated filer\", checkstart)\n",
    "                        find2 = checkextract.find(\"non-accelerated filer\", find1+10)\n",
    "                        find3 = checkextract.find(\"accelerated filer\", find2+10)\n",
    "                        find4 = checkextract.find(\"smaller reporting\", find3)\n",
    "                        find5 = find4+len(\"smaller reporting company\")+10\n",
    "                        LAF = checkextract[find1:find2]\n",
    "                        NAF = checkextract[find2:find3]\n",
    "                        AF = checkextract[find3:find4]\n",
    "                        if find5>len(checkextract):\n",
    "                            SRC = checkextract[find4:]\n",
    "                        else:\n",
    "                            SRC = checkextract[find4:find5]\n",
    "                    elif year >= 2005:\n",
    "                        find1 = checkextract.find(\"large accelerated\", checkstart)\n",
    "                        find2 = checkextract.find(\"non-accelerated filer\", find1+10)\n",
    "                        find3 = checkextract.find(\"accelerated\", find2+10)\n",
    "                        find4 = checkextract.find(\"indicate\", find3)\n",
    "                        LAF = checkextract[find1:find2]\n",
    "                        NAF = checkextract[find2:find3]\n",
    "                        if find4>0:\n",
    "                            AF = checkextract[find3:find4]\n",
    "                        else:\n",
    "                            AF = checkextract[find3:]\n",
    "                else:\n",
    "##                    print(sorterlister)\n",
    "##                    print(URLs[i])\n",
    "##                    print(sorter)\n",
    "                    filingstatus = \"error in sorting of filing status\"\n",
    "                if year >=2005:\n",
    "                    LAF2 = LAF.replace(\"large accelerated filer\", \" \")\n",
    "                    AF2 = AF.replace(\"accelerated filer\", \" \")\n",
    "                    NAF2 = NAF.replace(\"non-accelerated filer\", \" \")\n",
    "                    SRC2 = SRC.replace(\"smaller reporting company\", \" \")\n",
    "                    LAF2 = cleanreturns(LAF2)\n",
    "                    AF2 = cleanreturns(AF2)\n",
    "                    NAF2 = cleanreturns(NAF2)\n",
    "                    SRC2 = cleanreturns(SRC2)\n",
    "    ##                LAF2 = LAF2[0:LAF2.find(\" \")]\n",
    "    ##                AF2 = AF2[0:AF2.find(\" \")]                \n",
    "    ##                NAF2 = NAF2[0:NAF2.find(\" \")]\n",
    "    ##                SRC2 = SRC2[0:SRC2.find(\" \")]\n",
    "\n",
    "                    if year>=2008:\n",
    "                        if LAF2 == AF2 and AF2 == NAF2 and NAF2 != SRC2 :\n",
    "                            filingstatus = \"Smaller reporting company\"\n",
    "                        if LAF2 == AF2 and AF2 == SRC2 and AF2 != NAF2 :\n",
    "                            filingstatus = \"Non-accelerated filer\"\n",
    "                        if LAF2 == SRC2 and SRC2 == NAF2 and AF2 != SRC2 :\n",
    "                            filingstatus = \"Accelerated filer\"\n",
    "                        if LAF2 != AF2 and AF2 == NAF2 and NAF2 == SRC2 :\n",
    "                            filingstatus = \"Large accelerated filer\"\n",
    "                        \n",
    "                    elif year>=2005:\n",
    "                        if LAF2 == AF2 and AF2 != NAF2 :\n",
    "                            filingstatus = \"Non-accelerated filer\"\n",
    "                        if LAF2 == NAF2 and AF2 != NAF2 :\n",
    "                            filingstatus = \"Accelerated filer\"\n",
    "                        if LAF2 != AF2 and AF2 == NAF2 :\n",
    "                            filingstatus = \"Large accelerated filer\"\n",
    "                        \n",
    "                        \n",
    "##            if year >= 2005 and mode== \"1\":\n",
    "##                if i<60 or alternate_exists > 5:\n",
    "##                    a = time.time()\n",
    "##                    if i%500==0:\n",
    "##                        print(\"we're in here\")\n",
    "####                    print(\"checking for alternate\")\n",
    "##                    try:\n",
    "##                        datafull = urllib.request.urlopen(\"http://www.sec.gov/Archives/%s\" %(URLs[i]), timeout=10).read()\n",
    "##                        datafull = datafull.decode('utf-8')\n",
    "####                        datamax = max(datamax, len(datafull))\n",
    "##                        srchpt = datafull.rfind(\"entity filer category\")\n",
    "##                        dataexcerpt=datafull\n",
    "####                        b = time.time()\n",
    "####                        print(\"b-a is\", b-a)\n",
    "####                        print(\"length is\", len(datafull))\n",
    "##                        if srchpt!=-1:\n",
    "##                            dataexcerpt = datafull[srchpt:srchpt+1000]\n",
    "####                        print(len(dataexcerpt))\n",
    "##                        souptext = \"nothing was souped, it was too long\"\n",
    "##                        for parsing in parser_set:\n",
    "####                            print(parsing)\n",
    "##                            try:\n",
    "####                                if len(dataexcerpt)<500000:\n",
    "##                                soup = BeautifulSoup(dataexcerpt, parsing)\n",
    "##                                souptext = soup.get_text(\" \", strip=True)\n",
    "##\n",
    "##                ##            print(\"souped\")\n",
    "##                            except RuntimeWarning:\n",
    "##                                print(\"RUNTIME WARNING EXCEPTION\")\n",
    "####                                print(URLs[i])\n",
    "##                                problems.append([year, quarter, URLs[i], \"runtime warning 2\"])\n",
    "##                                continue\n",
    "##                            except KeyboardInterrupt:\n",
    "##                                raise KeyboardInterrupt\n",
    "##                                \n",
    "##                            except:\n",
    "##                                print(\"EXCEPTION within alternate check\")\n",
    "##                                problems.append([year, quarter, URLs[i], \"problem within alternate check\"])\n",
    "####                                print(URLs[i])\n",
    "##                                continue\n",
    "##                            break\n",
    "##                        datafull = souptext.lower()\n",
    "##                        searchpoint = datafull.rfind(\"entity filer category\")\n",
    "##                        searchstop = datafull.find(\"entity\", searchpoint + 3)\n",
    "####                        print(searchpoint, i)\n",
    "####                        c = time.time()\n",
    "####                        print(\"c-b is\", c-b)\n",
    "##                        if searchpoint != -1:\n",
    "##                            filerstatus_alternate = datafull[searchpoint:searchstop]\n",
    "##                            alternate_exists+=1\n",
    "####                            if alternate_exists==0:\n",
    "####                                alternate_exists = 1\n",
    "##                    except MemoryError:\n",
    "####                        print(\"memory error in souping\")\n",
    "##                        filerstatus_alternate = \"memory error\"\n",
    "##                    except KeyboardInterrupt:\n",
    "##                        raise KeyboardInterrupt\n",
    "####                    except:\n",
    "##                        print(\"Other error in souping\")\n",
    "##                        filerstatus_alternate = \"other error\"\n",
    "            if i%500==0:\n",
    "##                print(mktval)\n",
    "                print(i)\n",
    "##                print(\"alternate exists is\", alternate_exists)\n",
    "##                print(\"datamax is\", datamax)\n",
    "##                print(\"\\n \\n \\n\")\n",
    "                if i%1000==0:\n",
    "                    print(datetime.datetime.now())\n",
    "##            print(i)\n",
    "            rowtowrite.append([cik[i], name[i], forms[i], date[i], year, quarter, \"http://www.sec.gov/Archives/%s\" %(URLs[i]), mktval, largest, extract, pointofPF, checkboxes, checkextract, LAF, AF, NAF, SRC, LAF2, AF2, NAF2, SRC2, filingstatus, FYenddate, FY_year, accfilerpre2005,checkone, bartsection, filingstatus2]) ##, filerstatus_alternate])\n",
    "        except UnicodeDecodeError:\n",
    "            rowtowrite.append([cik[i], name[i], forms[i], date[i], year, quarter, \"http://www.sec.gov/Archives/%s\" %(URLs[i]), \"error processing unicode\"])\n",
    "            print(\"unicode error \\n\\n\\n\\n\")\n",
    "        with open(\"last_10k.txt\", \"w\") as text_file:\n",
    "            text_file.write(\"Last 10K was observation %s, CIK %s, name %s, and year %s quarter %s\" %(i, cik[i], name[i], year, quarter))\n",
    "    writecsv(rowtowrite, \"%s_%s_mktvals.csv\" %(year, quarter))\n",
    "    writecsv(problems, \"%s_%s_problems.csv\" %(year, quarter))\n",
    "    \n",
    "\n",
    "def isitmln(segment, startpoint):\n",
    "    nxtword_a = segment.find(\"$\", startpoint)\n",
    "    nxtword_b = segment.find(\" \", nxtword_a)\n",
    "    mlnword_end = segment.find(\" \", nxtword_b+1)\n",
    "    mlnword = segment[nxtword_b:mlnword_end].strip().lower().replace(\",\",\"\").replace(\".\",\"\")\n",
    "    return mlnword[0:7]\n",
    "\n",
    "def cleanreturns(stringseg):\n",
    "    bob = stringseg.replace(\"_\", \"\")\n",
    "    bob = bob.replace(\"[\", \"\")\n",
    "    bob = bob.replace(\"]\", \"\")\n",
    "    bob = bob.replace(\" \", \"\")\n",
    "    bob = bob.replace(\"_\", \"\")\n",
    "    return bob\n",
    "\n",
    "\n",
    "def filercatlooper(seg, mode=1):\n",
    "    return None\n",
    "\n",
    "def filercat(seg, mode=1):\n",
    "    filestatusmarks = [\"x\",\n",
    "                       \"Ã\",\n",
    "                       \"þ\",\n",
    "                       \"ü\",\n",
    "                       \"ý\"]\n",
    "    starts = False\n",
    "    filertyper = []\n",
    "    file = \"\"\n",
    "    if seg.find(\"[\")<seg.find(\"yes\") and seg.find(\"]\")>seg.find(\"yes\"):\n",
    "        seg = seg.replace(\"[\", \"\").replace(\"]\", \"\").strip()\n",
    "    if seg.find(\"[\")<seg.find(\"no\") and seg.find(\"]\")>seg.find(\"no\"):\n",
    "        seg = seg.replace(\"[\", \"\").replace(\"]\", \"\").strip()\n",
    "    if mode==1:\n",
    "##        seg = seg.replace(\"no\", \" no\")\n",
    "        breaks = [\"yes\", \"no\"]\n",
    "        breakpts = [\"y\", \"n\"]\n",
    "        sorterlister = [[\"yes\", seg.find(\"yes\"), \"yes\", \"accelerated filer\"],\n",
    "                        [\"no\", seg.find(\"no\"), \"no\", \"not an accelerated filer\"]]\n",
    "        sortedlist = sorted(sorterlister, key = lambda position: position[1])\n",
    "##        print(seg)\n",
    "##        print(sortedlist)\n",
    "\n",
    "    else:\n",
    "        breaks = [\"large accelerated filer\", \"accelerated filer\", \"non-accelerated filer\", \"smaller reporting company\"]\n",
    "##        print(seg)\n",
    "        breakpts = [\"l\", \"a\", \"n\", \"s\"]\n",
    "        seg = seg.replace(\"large accelerated filer\", \"lrg\")\n",
    "        seg = seg.replace(\"non-accelerated filer\", \"non\")\n",
    "        seg = seg.replace(\"accelerated filer\", \"acf\")\n",
    "        seg = seg.replace(\"smaller reporting company\", \"sml\")\n",
    "        sorterlister = [[\"LAF\", seg.find(\"lrg\"), \"lrg\", \"large accelerated filer\"],\n",
    "                        [\"AF\", seg.find(\"acf\"), \"acf\", \"accelerated filer\"],\n",
    "                        [\"NAF\", seg.find(\"non\"), \"non\", \"non-accelerated filer\"],\n",
    "                        [\"SRC\", seg.find(\"sml\"), \"sml\", \"smaller reporting company\"]]\n",
    "        sortedlist = sorted(sorterlister, key = lambda position: position[1])\n",
    "    \n",
    "##        print(seg)\n",
    "##        print(sortedlist)\n",
    "    if sortedlist==[] or len(sortedlist)==1:\n",
    "        return \"no filer category information\"\n",
    "    while sortedlist[0][1]==-1 and len(sortedlist)!=1:\n",
    "        del sortedlist[0]\n",
    "    if sortedlist==[] or len(sortedlist)==1:\n",
    "        return \"no filer category information\"\n",
    "\n",
    "\n",
    "    if sortedlist[0][1]==0:\n",
    "        starts = True\n",
    "    else:\n",
    "        starts = False\n",
    "    point = 0\n",
    "    for elem in range(len(sortedlist)):\n",
    "        if starts:\n",
    "            if elem !=len(sortedlist)-1:\n",
    "                filertyper.append([sortedlist[elem][0], seg[sortedlist[elem][1]+len(sortedlist[elem][2]):sortedlist[elem+1][1]].strip(), sortedlist[elem][3]])\n",
    "            else:\n",
    "                filertyper.append([sortedlist[elem][0], seg[sortedlist[elem][1]+len(sortedlist[elem][2]):].strip(), sortedlist[elem][3]])\n",
    "        else:\n",
    "            if elem==0:\n",
    "                filertyper.append([sortedlist[elem][0], seg[:sortedlist[elem][1]].strip(), sortedlist[elem][3]])\n",
    "            else:\n",
    "                filertyper.append([sortedlist[elem][0], seg[sortedlist[elem-1][1]+len(sortedlist[elem-1][2]):sortedlist[elem][1]].strip(), sortedlist[elem][3]])\n",
    "##    print(filertyper)\n",
    "    filertyper.sort()\n",
    "    for row in filertyper:\n",
    "        for fsm in filestatusmarks:\n",
    "            if fsm in row[1]:\n",
    "##                print(\"next observation\")\n",
    "##                print(filertyper)\n",
    "##                print(fsm)\n",
    "##                print(row[2])\n",
    "                return row[2]\n",
    "    if mode==1:\n",
    "##        print(filertyper)\n",
    "        if \"x\" in filertyper[1][1] or \"Ã\" in filertyper[1][1] or \"þ\" in filertyper[1][1] or \"ý\" in filertyper[1][1] or \"ü\" in filertyper[1][1]:\n",
    "            file = \"accelerated filer\"\n",
    "            return file\n",
    "        if \"x\" in filertyper[0][1] or \"Ã\" in filertyper[0][1] or \"þ\" in filertyper[0][1] or \"ý\" in filertyper[0][1] or \"ü\" in filertyper[0][1]:\n",
    "            file = \"not an accelerated filer\"\n",
    "            return file\n",
    "##        if file ==\"\":\n",
    "##            print(seg, filertyper)\n",
    "    else:\n",
    "##        print(\"filertyper\", filertyper)\n",
    "        comparer = []\n",
    "        for item in filertyper:\n",
    "            comparer.append(item[1].strip())\n",
    "        for element in range(len(comparer)):\n",
    "            comparer2=[]\n",
    "            if element!=0:\n",
    "                comparer2 = comparer[:element]\n",
    "            if element!=len(comparer)-1:\n",
    "                comparer2.extend(comparer[element+1:])\n",
    "##            print(\"comparer\", comparer)\n",
    "##            print(\"comparer 2\", comparer2)\n",
    "            \n",
    "            if comparer2.count(comparer2[0]) == len(comparer2) and comparer[element]!=comparer2[0]:\n",
    "##                print(filertyper[element][2])\n",
    "                return filertyper[element][2]\n",
    "##        print(comparer)\n",
    "##    for word in breaks:\n",
    "##        if seg[0] == word[0]:\n",
    "##            starts = True\n",
    "##            break\n",
    "##    indx = 0\n",
    "##    categ = \"none\"\n",
    "##    while categ==\"none\":\n",
    "##        categ = whichword(breaks, seg[indx:])\n",
    "##        if categ==\"none\":\n",
    "##            indx+=1\n",
    "##    if starts != 0:\n",
    "##        filertyper.append([categ, seg[:indx]])\n",
    "##    else:\n",
    "##        seg2 = seg[indx+1:]\n",
    "##        indx2 = 0\n",
    "##        categ2 = \"none\"\n",
    "##        while categ2==\"none\":\n",
    "##            categ2 = whichword(breaks, seg2[indx2:])\n",
    "##            if categ2==\"none\":\n",
    "##                indx2+=1\n",
    "##        filertyper.append([categ, seg2[:indx2]])\n",
    "##        \n",
    "\n",
    "\n",
    "\n",
    "    return file\n",
    "\n",
    "def whichword(listed, segment):\n",
    "    for word in listed:\n",
    "        if segment[0] == word[0]:\n",
    "            return word\n",
    "    return \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readfromweb complete\n",
      "readfromfile complete\n",
      "2014 1\n",
      "0\n",
      "2017-09-14 13:11:19.485302\n",
      "500\n",
      "1000\n",
      "2017-09-14 13:20:10.518222\n",
      "1500\n",
      "2000\n",
      "2017-09-14 13:28:07.221976\n",
      "2500\n",
      "3000\n",
      "2017-09-14 13:35:14.119085\n",
      "3500\n",
      "4000\n",
      "2017-09-14 13:42:57.619128\n",
      "4500\n",
      "5000\n",
      "2017-09-14 13:50:49.272838\n",
      "5500\n",
      "2017-09-14 13:58:34.775803\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "##    global mode\n",
    "##    mode = input(\"Enter 1 to attempt alternate downloading.  Enter anything else not to:\")\n",
    "##\n",
    "##    print(type(mode))\n",
    "##    print(mode)\n",
    "\n",
    "##    for year in range(1994,2016):\n",
    "    for year in range(2014,2015):\n",
    "        for quarter in range(1,2):\n",
    "##            year = 2003\n",
    "##            quarter = 1\n",
    "##            if year ==2007 and quarter==1:\n",
    "##                continue\n",
    "##            global alternate_exists\n",
    "##            alternate_exists= 0\n",
    "            if not os.path.exists(\"%s_%s.csv\" %(year, quarter)):\n",
    "                readindex(year, quarter)\n",
    "            print(year, quarter)\n",
    "##            readindex(year, quarter)\n",
    "            readforms(year, quarter)\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "def removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
